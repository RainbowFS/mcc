#!/usr/bin/env python3

import copy
import logging

LOG_FILENAME = 'mcc.log'
logging.basicConfig(
    filename=LOG_FILENAME,
    level=logging.DEBUG,
)

from mcr.libmcr import g5k, ApiError

from mcr.libsettings import *
import mcr.libsession
from mcr.libprint import print_items
import datetime
import dateutil.parser
import argparse
from mcr.libsalt import *
import threading
import dateutil


def get_sites(session):
    return g5k(session)("stable/sites").get_items()


def find_site_for_cluster(session, cluster):
    for site in g5k(session)("stable/sites").get_items():
        if cluster in g5k(session)("stable/sites")(site)("clusters").get_items():
            return site
    raise ApiError(404, "Cluster not found")


def get_link_href(entity, rel="self"):
    for item in entity["links"]:

        if item["rel"] == rel:
            return item["href"]
    return ""


def find_job(session, job, sites_hints=None):
    return find_sub_item(session, "jobs", int(job), sites_hints)


def find_dep(session, dep, sites_hints=None):
    return find_sub_item(session, "deployments", dep, sites_hints)


def print_site_item(session, items_name, uid, sites, filter, login):
    kwargs = {splat[0]: splat[1] for splat in (item.split("=") for item in filter)}
    kwargs["user_uid"] = login

    if opts.uid is None:
        for site in g5k(session)("stable")("sites").get_items():
            if sites is None or site in sites:
                return g5k(session)("stable")("sites")(site)(items_name).get_items_filtered(data=not opts.quiet,
                                                                                            **kwargs)

    else:

        return [g5k(session)(find_sub_item(session, items_name, uid, sites)).get_raw()]


def find_sub_item(session, item, uid, sites_hints):
    '''

    :param job: job uid
    :param sites_hints: list of possible sites to look for. If list is empty of None, all g5k sites are inspected
    :return: the url of the job
    '''

    if sites_hints is None or len(sites_hints) == 0:
        target_sites = g5k(session)("stable")("sites").get_items()
    else:
        target_sites = sites_hints

    for site in target_sites:
        try:
            items_for_site = g5k(session)("stable")("sites")(site)(item)(uid).get_raw()
            return get_link_href(items_for_site, rel="self")
        except ApiError as e:
            if e.return_code == 404:
                continue
            else:
                raise e

    return ""


def get_wall_time(duraction_adv, duration):
    if duraction_adv == "for":
        dt = (dateutil.parser.parse(duration) - dateutil.parser.parse("0h"))

    elif duraction_adv == "until":
        dt = (dateutil.parser.parse(duration) - datetime.datetime.now())

    return "%02d:%02d" % ((dt.seconds // 3600), (dt.seconds // 60) % 60)


def valid_oar_date(adate):
    return dateutil.parser.parse(adate)


class ParseSettings(argparse.Action):

    def __init__(self, option_strings, dest, nargs=None, **kwargs):
        super(ParseSettings, self).__init__(option_strings, dest, **kwargs)

    def __call__(self, parser, namespace, value, option_string=None):
        k, v = value.split('=')
        namespace.settings[k] = v


parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers(dest="command")
parser.add_argument("-q", help="quiet mode, just display the uids", action="store_true", dest="quiet")
parser.add_argument("--format", help="output formatting template, jinja", default=None)
parser.add_argument("--dry-run", help="just print the http requests", action="store_true", dest="dry")
parser.add_argument("--config",
                    help="path of the config file, by default mcc will look at a self.settings.yaml file in the current folder",
                    default=None)
parser.add_argument("-s", action=ParseSettings, help="override config file self.settings", nargs="*", default={},
                    dest="settings")

wait_parser = subparsers.add_parser("wait")
action_wait_parser = wait_parser.add_subparsers(dest="action")
kill_wait_parser = action_wait_parser.add_parser("kill")
kill_wait_parser.add_argument("uid", type=str, nargs='+', help='uid of the job to delete when killed')
kill_wait_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                              default=None)

alias_parser = subparsers.add_parser("alias")

action_alias_parser = alias_parser.add_subparsers(dest="action")
list_alias_parser = action_alias_parser.add_parser("list")
list_alias_parser.add_argument("uid", type=str, nargs='+', help='uids of the job sfor which to generate the aliases',
                               default=None)
list_alias_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                               default=None)

job_parser = subparsers.add_parser("job")

action_job_parser = job_parser.add_subparsers(dest="action")

list_job_parser = action_job_parser.add_parser("list")
list_job_parser.add_argument("uid", type=str, nargs='?', help='uid of the job to inspect', default=None)
list_job_parser.add_argument("--sites", type=str, nargs='*', help='list of sites for job search',
                             default=None)
list_job_parser.add_argument("--filter", type=str, nargs='*', help='list of filters to job seach, e.g. status=running',
                             default=[])

hosts_list_job_parser = action_job_parser.add_parser("hosts-list")
hosts_list_job_parser.add_argument("uid", type=int, nargs='?', help='uid of the job for which to show the hosts',
                                   default=None)
hosts_list_job_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                                   default=None)

add_job_parser = action_job_parser.add_parser("add")
add_job_parser.add_argument("site", type=str, help='site or cluster where to deploy the job')
add_job_parser.add_argument("node_count", type=int, help='how many node to book')
add_job_parser.add_argument("duration_adv", type=str, help='how many node to book', choices=["until", 'for'],
                            default="for")
add_job_parser.add_argument("duration", type=str, help='duration or expiration date for the job', default="1h")

plan_add_job_parserver = add_job_parser.add_subparsers(dest="effect_date")
future_plan_add_job_parserver = plan_add_job_parserver.add_parser("on")
future_plan_add_job_parserver.add_argument("date", help="date format is 'YYYY-MM-DD HH:MM:SS'", type=valid_oar_date)

now_plan_add_job_parserver = plan_add_job_parserver.add_parser("now")

wait_job_parser = action_job_parser.add_parser("wait")
wait_job_parser.add_argument("uid", type=str, help='uid of the job')
wait_job_parser.add_argument("--filter", type=str, help='wait until the condition is true e.g. state=running',
                             default="state=running")
wait_job_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                             default=None)

del_job_parser = action_job_parser.add_parser("del")
del_job_parser.add_argument("uid", type=str, nargs='*', help='list of uid(s) of the job(s) to delete')
del_job_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                            default=None)

install_job_parser = action_job_parser.add_parser("install")
install_job_parser.add_argument("uid", type=str, help='uid of the job to install to')
install_job_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                                default=None)

app_install_job_parser = install_job_parser.add_subparsers(dest="application")
salt_app_install_job_parser = app_install_job_parser.add_parser("salt")

dep_parser = subparsers.add_parser("dep")
action_dep_parser = dep_parser.add_subparsers(dest="action")

add_dep_parser = action_dep_parser.add_parser("add")
add_dep_parser.add_argument("uid", type=str, help='uid of the job on which to do the deployment')
add_dep_parser.add_argument("nodes", type=str, nargs='*',
                            help='names of the nodes on which to perform the deployement. all nodes from the job are deployed if ommited',
                            default=None)
add_dep_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                            default=None)
add_dep_parser.add_argument("--environment", type=str, help='name of the environment to install',
                            default="debian9-x64-base")

list_dep_parser = action_dep_parser.add_parser("list")
list_dep_parser.add_argument("uid", type=str, nargs='?', help='uid of the dep to inspect', default=None)
list_dep_parser.add_argument("--sites", type=str, nargs='*', help='list of sites for dep search')
list_dep_parser.add_argument("--filter", type=str, nargs='*',
                             help='list of filters to dep seach, e.g. state=running state!=error',
                             default=[])

list_dep_parser = action_dep_parser.add_parser("wait")
list_dep_parser.add_argument("uid", type=str, nargs='?', help='uid of the dep to inspect', default=None)
list_dep_parser.add_argument("--filter", type=str, nargs='*',
                             help='wait until the condition is true eg. status=terminate',
                             default="status=terminated")
list_dep_parser.add_argument("--site", type=str, nargs='?', help='hint of where the site job is',
                             default=None)

# Parse
opts = parser.parse_args()

settings = merge_settings(opts.config, opts.settings)

# default values

# can't have both -s default_site=... and --sites ...
if "default_site" in opts.settings and opts.__contains__("sites") and opts.sites is not None:
    print("Can't override both default site and possible sites")
    exit(1)

if opts.__contains__("site") and opts.site is None:
    opts.site = settings["default_site"]
if opts.__contains__("sites") and opts.sites is None:
    opts.sites = [settings["default_site"]]


# create API session


class Parsing():

    def __init__(self, **settings):
        self.settings = settings
        self.s = mcr.libsession.create_session(settings["api-backend"], self.settings["login"], self.settings["pwd"])

    def run(self):

        switch = {"job": self.handle_job, "dep": self.handle_dep, "alias": self.handle_alias, "wait": self.handle_wait}
        command = self.settings["command"]

        if command not in switch:
            parser.error('please specify an action: %s' % ", ".join(switch))
        action = self.settings["action"]

        switch[command](action)

    def handle_alias(self, action):
        switch = {"list": self.alias_list_print}

        if action not in switch:
            parser.error('please specify an action: %s' % ", ".join(switch))

        switch[action]()

    def handle_wait(self, action):

        import signal
        import time

        class GracefulKiller:
            kill_now = False

            def __init__(self):
                signal.signal(signal.SIGINT, self.exit_gracefully)
                signal.signal(signal.SIGTERM, self.exit_gracefully)

            def exit_gracefully(self, signum, frame):
                self.kill_now = True

        killer = GracefulKiller()
        while True:
            time.sleep(1)
            if killer.kill_now:
                self.job_del()
                break

    def handle_job(self, action):

        switch = {"list": self.job_list_print,
                  "add": self.job_add,
                  "del": self.job_del,
                  "wait": self.job_wait,
                  "hosts-list": self.job_host_list_print,
                  "install": self.job_install
                  }

        if action not in switch:
            parser.error('please specify an action: %s' % ", ".join(switch))
        switch[action]()

    def handle_dep(self, action):
        switch = {"add": self.dep_add,
                  "list": self.dep_list,
                  "wait": self.dep_wait}

        if action not in switch:
            parser.error('please specify an action: %s' % ", ".join(switch))

        switch[action]()

    def job_install(self):
        application = self.settings["application"]
        uid = self.settings["uid"]
        site = self.settings["site"]
        login = self.settings["login"]

        if application == "salt":
            threads = []
            ssh_key_file_private = self.settings["ssh_key_file_private"]
            salt_host_control_iface = self.settings["salt_host_control_iface"]
            ssh_key_file_private = self.settings["ssh_key_file_private"]

            for i, host in enumerate(self.job_host_list(uid, site)):
                if i == 0:
                    master_ip = get_ip(host, login, ssh_key_file_private, salt_host_control_iface
                                       )
                    master_hostname = host

                    print("master ip: %s" % master_ip)
                    print("installing master in %s" % host)

                    t = threading.Thread(target=install_salt_master,
                                         args=(
                                             host, ssh_key_file_private, "h0", master_ip, self.settings))
                    t.start()
                    threads.append(t)
                else:

                    print("installing minion in %s" % host)
                    t = threading.Thread(target=install_salt_minion,
                                         args=(
                                             host, ssh_key_file_private, "h%s" % i, master_ip, self.settings))
                    t.start()
                    threads.append(t)
            for t in threads:
                t.join()

                post_install_commands(master_hostname, ssh_key_file_private, self.settings)

            print("done")

    def job_list(self):

        filters = copy.copy(self.settings["filter"])
        filters.insert(0, "user_uid=%s" % self.settings["login"])
        uid = self.settings["uid"]
        sites = self.settings["sites"]
        login = self.settings["login"]

        if uid == "planned":  # a job is planed in the future and without error
            filters.insert(0, "started_at>=%d" % int(time.time()))
            filters.insert(0, "state!=error")
            uid = None

        res = print_site_item(self.s, "jobs", uid, sites, filters, login)
        return res

    def alias_list_print(self):

        for index, host in enumerate(
                [host for uid in self.settings["uid"] for host in self.job_host_list(uid, self.settings["site"])]):
            if index == 0:
                master_ip = get_ip(host, self.settings["login"], self.settings["ssh_key_file_private"],
                                   self.settings["salt_host_control_iface"])

                print(
                    "alias ssh%d=\"ssh -L 5011:%s:5011 -L 8888:%s:8888 -L 8086:%s:0886 -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -i %s root@%s\"" % (
                        index, master_ip, master_ip, master_ip, self.settings["g5k_ssh_key_file_private"],
                        host.replace("grid5000.fr", "g5k")))



            else:
                print(
                    "alias ssh%d=\"ssh -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -i %s root@%s\"" % (
                        index, self.settings["g5k_ssh_key_file_private"], host.replace("grid5000.fr", "g5k")))

    def job_list_print(self):
        res = self.job_list()
        print_items(res, self.settings["format"])

    def job_add(self):
        wt = get_wall_time(self.settings["duration_adv"], self.settings["duration"])
        properties = []
        resources = []
        # it sucks that we cannot have a dict, but we need to preserve key ordering for OAR
        resources.append(("nodes", self.settings["node_count"]))
        resources.append(("walltime", wt))

        if self.settings["effect_date"] == "on":
            reservation = self.settings["date"].strftime("%Y-%m-%d %H:%M:%S")  # in the future
        else:
            reservation = None  # now

        if self.settings["site"] in get_sites(self.s):
            site = self.settings["site"]
        else:
            properties.append(("cluster", "'%s'" % self.settings["site"]))
            site = find_site_for_cluster(self.s, self.settings["site"])

        job_uid = g5k(self.s)("stable")("sites")(site).post_job(resources=resources, properties=properties,
                                                                reservation=reservation,
                                                                queue=settings.get("default_queue", "default"))
        print(job_uid)

    def job_del(self):
        for uid in self.settings["uid"]:
            job_href = find_job(self.s, uid, None if self.settings["site"] is None else [self.settings["site"]])
            job_state = g5k(self.s)(job_href).get_raw()["state"]
            if job_state != "error":
                g5k(self.s)(job_href).delete()
                print("Job %s has been deleted " % job_href)
            else:
                print("Cannot del job %s since its state is %s " % (uid, job_state))

    def job_wait(self):
        job_href = find_job(self.settings["uid"], [self.settings["site"]])
        k, v = self.settings["filter"].split("=")
        job = g5k(self.s)(job_href).get_raw()
        while job[k] != v:
            if not self.settings["quiet"]:
                if "scheduled_at" in job:
                    minutes_remaining = (int(job["scheduled_at"]) - int(time.time())) // 60
                else:
                    minutes_remaining = "?"
                sys.stdout.write(
                    "\b" * 80 + " %s minutes remaining (is %s)" % (minutes_remaining, job["state"]))
                sys.stdout.flush()
                time.sleep(5)
                job = g5k(self.s)(job_href).get_raw()

    def job_host_list_print(self):
        hosts = self.job_host_list(self.settings["uid"], self.settings["site"])
        print("\n".join(hosts))

    def job_host_list(self, uid, site):
        job_href = find_job(uid, [site])
        job = g5k(self.s)(job_href).get_raw()
        if job["state"] == "running":
            return job["assigned_nodes"]
        else:
            raise Exception("Cannot show hosts, job is %s " % job["state"])

    def dep_add(self):
        job = g5k(self.s)(
            find_job(self.settings["uid"],
                     None if self.settings["site"] is None else [self.settings["site"]])).get_raw()
        if len(self.settings["nodes"]) == 0:
            node_list = job["assigned_nodes"]
        else:
            node_list = list(set(job["assigned_nodes"]) & set(self.settings["nodes"]))
        dep_uid = g5k(self.s)(get_link_href(job, "parent"))("deployments").post_provision(node_list=node_list,
                                                                                          key=settings["ssh_key"],
                                                                                          environment=self.settings[
                                                                                              "environment"],
                                                                                          notifications=["mailto:%s" %
                                                                                                         self.settings[
                                                                                                             "mailto"]])
        print(dep_uid)

    def dep_list(self):
        res = print_site_item("deployments", self.settings["uid"], self.settings["sites"], self.settings["filter"])
        print_items(res, self.settings["format"])

    def dep_wait(self):
        dep_href = find_dep(self.settings["uid"], [self.settings["site"]])
        k, v = self.settings["filter"].split("=")
        dep = g5k(self.s)(dep_href).get_raw()
        while dep[k] != v:
            if not self.settings["quiet"]:
                minutes_elapsed = (int(time.time()) - int(dep["created_at"])) // 60
                sys.stdout.write(
                    "\b" * 80 + "%s minutes elapsed (is %s)" % (minutes_elapsed, dep["status"]))
                sys.stdout.flush()
            time.sleep(10)
            dep = g5k(self.s)(dep_href).get_raw()


try:

    Parsing(**{**vars(opts), **settings}).run()
    exit(0)

except KeyboardInterrupt:
    pass
